{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2_V2.0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "## **Not an ideal network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24V2GQjlUPaJ",
        "colab_type": "text"
      },
      "source": [
        "**Program Name** :                     Not an ideal Network- Updated Version\n",
        "\n",
        "**Developed and updated by** : EVA Admin & Nihar Kanungo\n",
        "\n",
        "**Batch**  :                                      EVA Batch 2 Monday \n",
        "\n",
        "**Submitted Date** :                     29th July 2019\n",
        "\n",
        "# Abstract \n",
        "\n",
        "This Program describes the \"Not an Ideal Network\" scenario. That means there must be some code that is not used in ideal conditions. Let's explore the codes line by line and find out the piece of code that makes it not ideal. Once we figure out the code we may try to fix it if possible . \n",
        "\n",
        "So let's go ahead and see the codes . For easy understanding of the code we have added comments to each/most of the lines ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQJtviKVklS",
        "colab_type": "text"
      },
      "source": [
        "==============================================================================================================\n",
        "\n",
        "**Keras**  is a high level tensorflow API which is widely used for Deep Learning and Computer vision applications of Machine Learning \n",
        "The following lines of the code will install keras using pip and import keras and all it's functionalities to the notebook\n",
        "\n",
        "==============================================================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR0vwOEJzu9v",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install and import keras to this notebook\n",
        "# https://keras.io/\n",
        "\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJRbnXqFzyAr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6tu99gQWVTZ",
        "colab_type": "text"
      },
      "source": [
        "The following cell will import all necessary packages for runnning the algorithm to train the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {},
        "cellView": "code"
      },
      "source": [
        "'''\n",
        "Import \n",
        "       numpy                   -   for numerical operations\n",
        "       Sequential API of keras -   for model training\n",
        "                Flatten        -   which is used to convert the data into 1D vector\n",
        "                2D convolution -   for convolution of 2D images\n",
        "                np_utils                                                and \n",
        "                mnist dataset  -   which is a set of handwritten digits)\n",
        "'''\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Convolution2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88i1jqp3z1HT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtqr-YZpXqwA",
        "colab_type": "text"
      },
      "source": [
        "MNIST is a popular dataset which includes all the handwritten digits. MNIST typically comes with Train and Test Split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Load the MNIST data into the defined variables \n",
        "\n",
        "1. X_train and X_test are the features \n",
        "2. y_train & y_test are the target variables  \n",
        "'''\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAY7XxDRz2Te",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "2210d159-8e8d-4c5c-88c4-14a008635fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "'''\n",
        "Matplotlib is a very popular package used for data visualization primarily by plotting charts/graphs for Exploratory Data Analytics. \n",
        "The visual representation provides a great amount of information to data analysts for future actions to be taken. This notebook has \n",
        "been added matplotlib inline to display visualization in the notebook cell \n",
        "\n",
        "'''\n",
        "\n",
        "print (X_train.shape)  # print the shape of the training features\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0]) # display the first training data"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8677663f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHmAwq7Tz4Hk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshapes the training and testing features to 28 * 28 image size with single channel .\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkZveenz5a1",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In Keras the data has to be converted into float 32 . \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "'''\n",
        " Normalization/Standardization is an important aspect of the data/features to ensure that the data points are in a specfic range . The following lines of code \n",
        " will divide each data point in training and testing data by 255 to keep the number with in 0-1 .255 refers to the value of the colors .\n",
        "'''\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPn6aMKhz6jD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "0da160fc-f0fc-47e8-cbe1-15118e44f857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "y_train[:10] # display the first 10 training levels"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prJNU2pY0BfT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LaTNYR60DwU",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "34dc6557-deef-491a-90a3-f5e63aefd685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# The converted target training values after modified as 10-dimensional class matrices. This process is also known as one hot encoding \n",
        "Y_train[:10]\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCtqjxR2i16y",
        "colab_type": "text"
      },
      "source": [
        "The Following lines of code are the heart of the model training . it includes\n",
        "1. Import the Activation function ( Sigmoid, tanh,Relu etc.)\n",
        "2. Import 2D Maxpooling which can be used in conjuction with the Convolution layer\n",
        "3. Use multiple convolution functions on the input image\n",
        "4. Add Flatten Layer\n",
        "5. Add Softmax Activation to find out the Target with maximum proability \n",
        "6. Print the Model Summary\n",
        "7. Compile the model using \n",
        "\n",
        "    a. adam optimizer ( Popular optimizer is SGD) \n",
        "    b. Loss function as categorical crossentropy\n",
        "    c. Evaluation method as Accuracy of the prediction\n",
        "    \n",
        "8. Fit the training data using the complied model with the following hyper parameters\n",
        "\n",
        "    a. Batch size of 32\n",
        "    b. for 10 iterations for the training data \n",
        "    c. An animated progress bar for Verbose=1\n",
        "    \n",
        "9. Fit the model with the input data (X_train) against the target (Y_train)\n",
        "10. Print the Model as trained \n",
        "11. Predict the test data using the model trained \n",
        "12. Print the prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "b6ee809a-2b63-4263-9fcf-d53370ef726d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Import Activation and Maxpooling from keras which would be used for model training  \n",
        "\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "model = Sequential() \n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) # Input image - 28* 28*1 , Kernel size : 3 * 3 * 1  , No of kernels 32 , Output 26 * 26 * 32\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # Input image - 26* 26*32 , Kernel size : 3 * 3 * 32  , No of kernels 64 , Output 24 * 24 * 64\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # Input image - 24* 24*64 , Kernel size : 3 * 3 * 64  , No of kernels 128 , Output 22 * 22 * 128\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # Input image - 22* 22*128 , Max pooling : 2 * 2   , Output 11 * 11 * 256\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # Input image - 11* 11*256 , Kernel size : 3 * 3 * 256  , No of kernels 256 , Output 9 * 9 * 256\n",
        "\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # Input image - 9* 9*256 , Kernel size : 3 * 3 * 256  , No of kernels 512 , Output 7 * 7 * 512\n",
        "\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # Input image - 7* 7*512 , Kernel size : 3 * 3 * 512  , No of kernels 1024 , Output 5 * 5 * 1024\n",
        "\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))# Input image - 5* 5*1024 , Kernel size : 3 * 3 * 1024  , No of kernels 2048, Output 3 * 3 * 2048\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # Input image - 3* 3*2048 , Kernel size : 3 * 3 * 2048  , No of kernels 10 , Output 1 * 1 * 10\n",
        "\n",
        "model.add(Flatten()) # flattens the matrix/tensor into one dimension\n",
        "\n",
        "model.add(Activation('softmax')) # Apply the Softmax activation on the output value to find out the class with more weightage\n",
        "\n",
        "model.summary() # Display the model summary"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_57 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_64 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "compile the model using the following hyper parameters\n",
        "    a. adam optimizer ( Popular optimizer is SGD) \n",
        "    b. Loss function as categorical crossentropy\n",
        "    c. Evaluation method as Accuracy of the prediction\n",
        "\n",
        "'''\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "34c87725-8bc7-46aa-fc81-52a1f96f4555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Fit the training data into the model for 10 epochs \n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 222s 4ms/step - loss: 1.2398 - acc: 0.4908\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 221s 4ms/step - loss: 1.1852 - acc: 0.5005\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1697 - acc: 0.5025\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1668 - acc: 0.5022\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1629 - acc: 0.5027\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1672 - acc: 0.5012\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1548 - acc: 0.5039\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 1.1611 - acc: 0.5034\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 219s 4ms/step - loss: 1.1635 - acc: 0.5026\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 219s 4ms/step - loss: 1.1610 - acc: 0.5027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86775aaac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6f27a72-dc4f-4b7c-c7a1-221f56f4ff0a"
      },
      "source": [
        "# Evaluate the test data using the model trained above and find out the validation score\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "# print the validation score of the model \n",
        "print(score)\n",
        "\n",
        "# predicted target of the test data \n",
        "y_pred = model.predict(X_test)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1707711936950684, 0.4994]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx0svhrE4JXp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "06ac764f-2c81-435a-fa06-a0242a75d73d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "\n",
        "# print the predicted target and the actual target\n",
        "\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.5427863e-14 2.5427863e-14 2.5427863e-14 2.5427863e-14 2.5427863e-14\n",
            "  2.5427863e-14 2.5427863e-14 1.0000000e+00 2.5427863e-14 2.5427863e-14]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [1.0048441e-09 1.0000000e+00 1.0048441e-09 1.0048441e-09 1.0048441e-09\n",
            "  1.0048441e-09 1.0048441e-09 1.0048441e-09 1.0048441e-09 1.0048441e-09]\n",
            " [1.0000000e+00 8.8584066e-13 8.8584066e-13 8.8584066e-13 8.8584066e-13\n",
            "  8.8584066e-13 8.8584066e-13 8.8584066e-13 8.8584066e-13 8.8584066e-13]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [3.2569356e-10 1.0000000e+00 3.2569356e-10 3.2569356e-10 3.2569356e-10\n",
            "  3.2569356e-10 3.2569356e-10 3.2569356e-10 3.2569356e-10 3.2569356e-10]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0s1Mk4eiHbn",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        "---------------------\n",
        "\n",
        "1. The Training Time of this Model is very high due to \n",
        "      i) The Number of Kernels increases for each convolution layer \n",
        "      ii) The Total number of parameters increases a  lot for every convolution layer until the receptive\n",
        "           field becomes the size of the image\n",
        "2. The model seems to over train  as we are trying to find a lot of edges and gradients from images of \n",
        "     28 * 28 size\n",
        "3. The Number of classes are 10 where as we are using a lot of kernels ( 32- 2048 ). That creates a lot of image in the memory and the processor becomes very slow due to excessive use of the memory\n",
        "4. The Accuracy of the model is less as the model over trains itself \n",
        "\n",
        "**Major Problem Identified **\n",
        "\n",
        "The Model directly lowers the number of kernels from 2048 to 10. This takes out all the major learnings that the model learned by performing multiple convolution operations. Hence the accuracy is very low \n",
        "\n",
        "**Fix**\n",
        "\n",
        "It's important to preserve the understanding/learning by using a 1*  1 kernel and 10 of them. By doing this we will fit the features of all those 2048 channels into 10 and then perform a convolution of 3* 3 and 10 of them in order to map it to the number of output classes.\n",
        "\n",
        "The following is the code which fixed the problem and got a better accuracy\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOl2VbxAnWJE",
        "colab_type": "code",
        "outputId": "91e87df2-9e68-4c9e-fd3d-597550689f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model = Sequential() \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) \n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_74 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_80 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_81 (Conv2D)           (None, 3, 3, 10)          20490     \n",
            "_________________________________________________________________\n",
            "conv2d_82 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,185,432\n",
            "Trainable params: 25,185,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 223s 4ms/step - loss: 0.2364 - acc: 0.9261\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 221s 4ms/step - loss: 0.0652 - acc: 0.9818\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 221s 4ms/step - loss: 0.0511 - acc: 0.9861\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0416 - acc: 0.9889\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0347 - acc: 0.9908\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0308 - acc: 0.9916\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0270 - acc: 0.9927\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0267 - acc: 0.9928\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0225 - acc: 0.9942\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0233 - acc: 0.9938\n",
            "[[1.2112999e-19 2.5462067e-15 1.2112999e-19 1.6890652e-12 1.2112999e-19\n",
            "  2.5732050e-15 1.2112999e-19 1.0000000e+00 1.2112999e-19 6.5983704e-13]\n",
            " [9.9177763e-11 9.9177763e-11 1.0000000e+00 9.9177763e-11 9.9177763e-11\n",
            "  9.9177763e-11 9.9177763e-11 9.9177763e-11 9.9177763e-11 9.9177763e-11]\n",
            " [2.6872512e-13 1.0000000e+00 1.3275813e-09 3.4228436e-13 2.6872512e-13\n",
            "  2.6872512e-13 2.6872512e-13 3.2115033e-10 7.3133430e-11 2.6872512e-13]\n",
            " [9.9999940e-01 4.3285038e-09 4.3285038e-09 4.3285038e-09 4.3285038e-09\n",
            "  2.1040411e-07 1.9526819e-08 4.9635438e-09 4.3285038e-09 3.8278816e-07]\n",
            " [3.7395468e-14 3.7395468e-14 3.7395468e-14 3.7395468e-14 1.0000000e+00\n",
            "  3.7395468e-14 3.7395468e-14 3.7395468e-14 3.7395468e-14 1.2388829e-12]\n",
            " [9.7223314e-15 1.0000000e+00 2.5177491e-10 9.7223314e-15 9.7223314e-15\n",
            "  9.7223314e-15 9.7223314e-15 4.1277550e-12 9.7464141e-11 9.7223314e-15]\n",
            " [1.3057194e-15 3.1360800e-10 1.3057194e-15 1.3057194e-15 1.0000000e+00\n",
            "  2.4747806e-13 1.3057194e-15 9.2592687e-13 2.3169175e-13 4.5239507e-12]\n",
            " [4.0019477e-09 4.0019477e-09 4.0019477e-09 9.3548221e-07 4.3338723e-04\n",
            "  8.6867917e-09 4.0019477e-09 1.2362757e-07 2.5120205e-08 9.9956554e-01]\n",
            " [1.8217729e-11 1.8217729e-11 1.8217729e-11 1.8217729e-11 1.8217729e-11\n",
            "  9.9999654e-01 1.6005160e-07 1.8217729e-11 3.3810184e-06 1.8217729e-11]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2tRFTqAUril",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "469ee18b-4e8e-4ebe-f192-cea1209c73a3"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03809279111000642, 0.9914]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8dqjUiM4Vjl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14Oi0erI4hSG",
        "colab_type": "text"
      },
      "source": [
        "***We are not yet there ***\n",
        "\n",
        "After Training the above model i was thinking to have corrected all the issues of the 1st model as the accuracy of the above model is not bad . But I was surprised to know that I was wrong . The actual problem of the model was not that . Let's run the 1st model as it's with a very small fix and see how it works. If it performs well then we will figure out what changes we did to the first model to get a better accuracy.\n",
        "\n",
        "So let's run the below network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6zInjek8ZQZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hO4Nr-P28ZkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5315e29c-07ea-4ece-b271-97608790f07c"
      },
      "source": [
        "# Import Activation and Maxpooling from keras which would be used for model training  \n",
        "\n",
        "model = Sequential() \n",
        "\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) # Input image - 28* 28*1 , Kernel size : 3 * 3 * 1  , No of kernels 32 , Output 26 * 26 * 32\n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # Input image - 26* 26*32 , Kernel size : 3 * 3 * 32  , No of kernels 64 , Output 24 * 24 * 64\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # Input image - 24* 24*64 , Kernel size : 3 * 3 * 64  , No of kernels 128 , Output 22 * 22 * 128\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # Input image - 22* 22*128 , Max pooling : 2 * 2   , Output 11 * 11 * 256\n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # Input image - 11* 11*256 , Kernel size : 3 * 3 * 256  , No of kernels 256 , Output 9 * 9 * 256\n",
        "\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # Input image - 9* 9*256 , Kernel size : 3 * 3 * 256  , No of kernels 512 , Output 7 * 7 * 512\n",
        "\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # Input image - 7* 7*512 , Kernel size : 3 * 3 * 512  , No of kernels 1024 , Output 5 * 5 * 1024\n",
        "\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))# Input image - 5* 5*1024 , Kernel size : 3 * 3 * 1024  , No of kernels 2048, Output 3 * 3 * 2048\n",
        "\n",
        "model.add(Convolution2D(10, 3, 3)) # Input image - 3* 3*2048 , Kernel size : 3 * 3 * 2048  , No of kernels 10 , Output 1 * 1 * 10\n",
        "\n",
        "model.add(Flatten()) # flattens the matrix/tensor into one dimension\n",
        "\n",
        "model.add(Activation('softmax')) # Apply the Softmax activation on the output value to find out the class with more weightage\n",
        "\n",
        "model.summary() # Display the model summary\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_91 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 223s 4ms/step - loss: 0.1501 - acc: 0.9530\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0540 - acc: 0.9851\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0449 - acc: 0.9874\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 221s 4ms/step - loss: 0.0331 - acc: 0.9899\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0290 - acc: 0.9915\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0257 - acc: 0.9929\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0228 - acc: 0.9935\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0221 - acc: 0.9940\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 221s 4ms/step - loss: 0.0184 - acc: 0.9945\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 220s 4ms/step - loss: 0.0168 - acc: 0.9956\n",
            "[[4.2433839e-17 6.7137881e-15 8.0897793e-14 2.2852810e-14 8.3670354e-12\n",
            "  2.4273572e-14 5.3438334e-19 1.0000000e+00 4.0143687e-17 2.9404031e-11]\n",
            " [1.2037920e-18 1.3042650e-16 1.0000000e+00 1.3289007e-21 9.9939535e-20\n",
            "  7.2995913e-25 3.3703861e-14 1.4786701e-24 3.6976398e-20 1.6492617e-23]\n",
            " [3.0879935e-15 1.0000000e+00 8.6344565e-13 2.2886113e-16 1.5871168e-09\n",
            "  8.7023775e-09 3.0273773e-11 1.7593239e-12 1.0392502e-12 1.1063931e-14]\n",
            " [9.9999928e-01 6.0578738e-18 3.6619450e-14 1.7684781e-11 9.2680922e-14\n",
            "  1.1845058e-12 7.6408634e-07 7.9739933e-17 1.5287439e-13 2.4049979e-12]\n",
            " [7.4462682e-23 4.6338864e-26 2.6224102e-27 3.2940108e-27 1.0000000e+00\n",
            "  2.9366655e-29 1.3819942e-24 1.0252684e-25 6.4209669e-24 3.0468585e-26]\n",
            " [2.2047222e-19 1.0000000e+00 4.0727204e-17 2.0353714e-22 1.5003679e-11\n",
            "  2.1981956e-13 9.2520918e-15 4.6399597e-16 7.6696351e-16 1.6766757e-19]\n",
            " [1.5292154e-23 4.7346567e-14 6.9536323e-19 3.9518262e-19 1.0000000e+00\n",
            "  1.2684030e-15 1.9207643e-19 2.5276862e-13 2.7226134e-12 2.3238370e-15]\n",
            " [1.2989741e-13 3.6238670e-20 1.1029739e-13 1.5430870e-14 5.3833465e-10\n",
            "  1.2323400e-13 8.5594822e-18 1.5365596e-16 1.9753105e-14 1.0000000e+00]\n",
            " [7.0960626e-15 5.4986003e-22 3.8855685e-20 3.8319101e-15 3.9948478e-21\n",
            "  9.9998355e-01 1.4852424e-06 2.2884467e-20 1.5068952e-05 4.3675783e-13]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ljXnDj9ltpG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "debeee3b-372a-4ed5-c4dd-1afa10ff3fae"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03655209561262977, 0.9915]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gSSBXBulyYV",
        "colab_type": "text"
      },
      "source": [
        "Wow ! . The Score is now 99.15% . How did that happen ? Now let's compare the 1st Network and 3rd Network to see who was the villian .\n",
        "\n",
        "Did we spot it correctly ? No ? Let's do a close comparision again . I am sure this time we found it .\n",
        "\n",
        "Yes it's none other than the Activation function relu which was used in the layer just before taking the softmax in the 1st Network .\n",
        "\n",
        "But why ? It's because relu throws away all negative values and makes it zero. Now when the softmax function sees this value it has no idea how negative that number was ? So it gives same importance to zeros which were actually negative numbers .\n",
        "\n",
        "That makes the network weak in learning and gives a very poor Training and validation accuracy "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWFvgzxtn_64",
        "colab_type": "text"
      },
      "source": [
        "***Summary ***\n",
        "\n",
        "\n",
        "The following points to be considering while designing a Convolution model \n",
        "\n",
        "1. The Size of kernels and number of kernels for each convolution layer must be carefully decided \n",
        "2. The Number of kernels must be in line with the number of classes ( must not be less , must not be high)\n",
        "3. The Hyper parameters must be choosen based on experience and learnings from multiple outcomes \n",
        "4. The Optimizer and Loss function must be choosen carefully and based on the data we are trying to fit \n",
        "5. Proper Normalization technique must be used   and now the most important\n",
        "6. DON'T EVER USE \"relu \" IN THE LAYER JUST BEFORE YOU TAKE SOFTMAX \n",
        "\n",
        "The Process of getting the best fit model is also iterative in nature and data hungry. Care must be taken to get a perfect fit model and not an overfit or underfit one \n",
        "\n",
        "\n",
        "\n",
        "*********************************************************************************************************************************"
      ]
    }
  ]
}