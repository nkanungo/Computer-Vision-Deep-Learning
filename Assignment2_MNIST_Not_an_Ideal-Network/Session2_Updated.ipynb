{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session2_Updated.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nJ7YEw_vyjG",
        "colab_type": "text"
      },
      "source": [
        "# **Not an ideal network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24V2GQjlUPaJ",
        "colab_type": "text"
      },
      "source": [
        "# Program Name : Not an ideal Network- Updated Version\n",
        "# Developed and updated by : EVA Admin & Nihar Kanungo\n",
        "# Batch  : EVA Batch 2 Monday \n",
        "# Submitted Date : 29th July 2019\n",
        "# Abstract \n",
        "\n",
        "This Program describes the \"Not an Ideal Network\" scenario. That means there must be some code that is not used in ideal conditions. Let's explore the codes line by line and find out the piece of code that makes it not ideal. Once we figure out the code we may try to fix it if possible . \n",
        "\n",
        "So let's go ahead and see the codes . For easy understanding of the code we have added comments to each/most of the lines ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQJtviKVklS",
        "colab_type": "text"
      },
      "source": [
        "==============================================================================================================\n",
        "\n",
        "Keras  is a high level tensorflow API which is widely used for Deep Learning and Computer vision applications of Machine Learning \n",
        "The following lines of the code will install keras using pip and import keras and all it's functionalities to the notebook\n",
        "\n",
        "==============================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGWv5hBhv2jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Keras using pip \n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "# import keras library into the jupyter notebook\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6tu99gQWVTZ",
        "colab_type": "text"
      },
      "source": [
        "The following cell will import all necessary packages for runnning the algorithm to train the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnMlDJQKv4VG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing numpy will inclide all the mathematical features ( matrix, vector etc..) to the program\n",
        "import numpy as np\n",
        "\n",
        "# importing the sequential API of keras to the notebook. The sequential API allows to create model layer by layer for most of the problems\n",
        "from keras.models import Sequential\n",
        "# Import Flatten which is required to convert the images into matrix format which can be trained using the Sequential API\n",
        "from keras.layers import Flatten\n",
        "# Import 2D convolution features\n",
        "from keras.layers import Convolution2D\n",
        "# Import the numpy utilities \n",
        "from keras.utils import np_utils\n",
        "# Import the mnist dataset which is a corpus of all handwritten digits \n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtqr-YZpXqwA",
        "colab_type": "text"
      },
      "source": [
        "MNIST is a popular dataset which includes all the handwritten digits. MNIST typically comes with Train and Test Split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdSu2lMwB9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the MNIST data into the variables defined in the program . X_train and X_test are the features where as y_train & y_test are the target variables  \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLaDf0-rwCmj",
        "colab_type": "code",
        "outputId": "8757bb6d-a61e-442d-ed1b-a0c8ed3bd019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# The following line of code will print the shape of the training features in the cell of the notebook . \n",
        "print (X_train.shape)\n",
        "#************************************************************************************************************************************** \n",
        "# Matplotlib is a very popular package used for data visualization primarily by plotting charts/graphs for Exploratory Data Analytics. \n",
        "# The visual representation provides a great amount of information to data analysts for future actions to be taken \n",
        "#************************************************************************************************************************************** \n",
        "from matplotlib import pyplot as plt\n",
        "# This line of code will display the output inline without the user explicitely asking the code to plot the chart/graph\n",
        "%matplotlib inline\n",
        "# This line of code plot the data with index 0 ( the first one only)\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0907586198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erb11jNwwFwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The following lines of code reshapes the training and testing features to 28 * 28 image size with single channel .\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLK4YDoRwHet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In Keras the data has to be converted into a specific format which is float 32 . The following lines of code converts the data format into Float32 .\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "#*************************************************************************************************************************************************************************** \n",
        "# Normalization/Standardization is an important aspect of the data/features to ensure that the data points are in a specfic range . The following lines of code will divide \n",
        "# each data point in training and testing data by 255 to keep the number with in 0-1 .255 refers to the value of the colors .\n",
        "#*************************************************************************************************************************************************************************** \n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKLOmhlwJQl",
        "colab_type": "code",
        "outputId": "6b8538dd-31bb-42d7-81a6-86118a0881be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The following line of code display the first 10 training levels .The levels here are the digits that are written\n",
        "y_train[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YusMJguiwKsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upxc99AswMW0",
        "colab_type": "code",
        "outputId": "d033ffd2-c6f8-463f-baae-c64e793f6996",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# The converted target training values after modified as 10-dimensional class matrices. This process is also known as one hot encoding \n",
        "Y_train[:10]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCtqjxR2i16y",
        "colab_type": "text"
      },
      "source": [
        "The Following lines of code are the heart of the model training . it includes\n",
        "1. Import the Activation function ( Sigmoid, tanh,Relu etc.)\n",
        "2. Import 2D Maxpooling which can be used in conjuction with the Convolution layer\n",
        "3. Use multiple convolution functions on the input image\n",
        "4. Add Flatten Layer\n",
        "5. Add Softmax Activation to find out the Target with maximum proability \n",
        "6. Print the Model Summary\n",
        "7. Compile the model using \n",
        "\n",
        "    a. adam optimizer ( Popular optimizer is SGD) \n",
        "    b. Loss function as categorical crossentropy\n",
        "    c. Evaluation method as Accuracy of the prediction\n",
        "    \n",
        "8. Fit the training data using the complied model with the following hyper parameters\n",
        "\n",
        "    a. Batch size of 32\n",
        "    b. for 10 iterations for the training data \n",
        "    c. An animated progress bar for Verbose=1\n",
        "    \n",
        "9. Fit the model with the input data (X_train) against the target (Y_train)\n",
        "10. Print the Model as trained \n",
        "11. Predict the test data using the model trained \n",
        "12. Print the prediction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irTVUE47wNwr",
        "colab_type": "code",
        "outputId": "f15caf83-6ac6-48d4-d93b-5e710c7f076f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "# Print the import statements \n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "# define the keras sequential model which can train multiple layers \n",
        "model = Sequential() \n",
        "\n",
        "# Add a convolution layer with 32 kernels of size 3*3 on input image of size 28 * 28\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) # Input image - 28* 28*1 , Kernel size : 3 * 3 * 1  , No of kernels 32 , Output 26 * 26 * 32\n",
        "\n",
        "# Add a convolution layer with 64 kernels of size 3*3 * 32 on input  of size 26 * 26 * 32\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) # Input image - 26* 26*32 , Kernel size : 3 * 3 * 32  , No of kernels 64 , Output 24 * 24 * 64\n",
        "\n",
        "# Add a convolution layer with 128 kernels of size 3*3* 64 on input  of size 24 * 24 * 64\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu')) # Input image - 24* 24*64 , Kernel size : 3 * 3 * 64  , No of kernels 128 , Output 22 * 22 * 128\n",
        "\n",
        "# Maxpooling layer of size 2*2 applied on the above output \n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) # Input image - 22* 22*128 , Max pooling : 2 * 2   , Output 11 * 11 * 256\n",
        "\n",
        "# Add a convolution layer with 256 kernels of size 3*3* 256 on input  of size 11 * 11 * 256\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu')) # Input image - 11* 11*256 , Kernel size : 3 * 3 * 256  , No of kernels 256 , Output 9 * 9 * 256\n",
        "\n",
        "# Add a convolution layer with 512 kernels of size 3*3* 256 on input  of size 9 * 9 * 256\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu')) # Input image - 9* 9*256 , Kernel size : 3 * 3 * 256  , No of kernels 512 , Output 7 * 7 * 512\n",
        "\n",
        "# Add a convolution layer with 1024 kernels of size 3*3* 512 on input  of size 7 * 7 * 512\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu')) # Input image - 7* 7*512 , Kernel size : 3 * 3 * 512  , No of kernels 1024 , Output 5 * 5 * 1024\n",
        "\n",
        "# Add a convolution layer with 2048 kernels of size 3*3* 1024 on input  of size 5 * 5* 1024\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))# Input image - 5* 5*1024 , Kernel size : 3 * 3 * 1024  , No of kernels 2048, Output 3 * 3 * 2048\n",
        "\n",
        "# Add a convolution layer with 10 kernels (no of classes) of size 3*3* 2048 on input  of size 3 * 3* 2048\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) # Input image - 3* 3*2048 , Kernel size : 3 * 3 * 2048  , No of kernels 10 , Output 1 * 1 * 10\n",
        "\n",
        "# flattens the matrix/tensor into one dimension\n",
        "model.add(Flatten())\n",
        "# Apply the Softmax activation on the output value to find out the class with maximum probability as the predicted class/digit to be specific \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 18:17:07.452833 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "W0727 18:17:07.506783 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 18:17:07.514401 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "W0727 18:17:07.565508 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          184330    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,348,362\n",
            "Trainable params: 25,348,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZOpRb6yG7_",
        "colab_type": "code",
        "outputId": "47587c88-c65c-4714-c9c5-da3adf5e32cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# compile the model using the following hyper parameters\n",
        "#    a. adam optimizer ( Popular optimizer is SGD) \n",
        "#    b. Loss function as categorical crossentropy\n",
        "#    c. Evaluation method as Accuracy of the prediction\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0727 18:23:01.276613 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 18:23:01.310328 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O248wVQyMft",
        "colab_type": "code",
        "outputId": "c18e2858-9a1f-44a1-fb7c-f820f07a485c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# Fit the training data into the model for 10 epochs \n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n",
            "W0727 18:23:35.059998 140247618705280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 18:23:35.144067 140247618705280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 117s 2ms/step - loss: 1.6094 - acc: 0.4157\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4407 - acc: 0.4817\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4290 - acc: 0.4850\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4286 - acc: 0.4849\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4261 - acc: 0.4853\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4197 - acc: 0.4873\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4174 - acc: 0.4873\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4251 - acc: 0.4857\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4192 - acc: 0.4872\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 113s 2ms/step - loss: 1.4278 - acc: 0.4851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8da2ff4c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sst4KneiyOL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the test data using the model trained above and find out the score \n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfJiXOKsyj4y",
        "colab_type": "code",
        "outputId": "3a126536-691f-4d3f-d465-30716ef089fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# print the score of the model evaluation \n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.4311341636657715, 0.485]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwLSXt7nyn_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This line of code will predict the target of the test data using .predict if the model trained above\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWKKoOKwyppN",
        "colab_type": "code",
        "outputId": "7a6be1e1-f49d-4692-cd61-d33a97440760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# print the predicted target \n",
        "print(y_pred[:9])\n",
        "# print the actual target\n",
        "print(y_test[:9])\n",
        "# This would help to understand how good/bad the model is in predicting the output . This is a good indication if the model needs to be reworked . \n",
        "# While accuracy depends on the domain and the degree of acceptability , a data scientist should always try to find parameters to increase the true positive prediction "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [3.5189401e-22 3.5189401e-22 1.0000000e+00 3.5189401e-22 3.5189401e-22\n",
            "  3.5189401e-22 3.5189401e-22 3.5189401e-22 3.5189401e-22 3.5189401e-22]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [3.6690793e-25 3.6690793e-25 3.6690793e-25 3.6690793e-25 1.0000000e+00\n",
            "  3.6690793e-25 3.6690793e-25 3.6690793e-25 3.6690793e-25 3.6690793e-25]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [6.8876398e-17 6.8876398e-17 6.8876398e-17 6.8876398e-17 1.0000000e+00\n",
            "  6.8876398e-17 6.8876398e-17 6.8876398e-17 6.8876398e-17 6.8876398e-17]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]\n",
            " [1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01\n",
            "  1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01 1.0000000e-01]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0s1Mk4eiHbn",
        "colab_type": "text"
      },
      "source": [
        "**Observation**\n",
        "---------------------\n",
        "\n",
        "1. The Training Time of this Model is very high due to \n",
        "      i) The Number of Kernels increases for each convolution layer \n",
        "      ii) The Total number of parameters increases a  lot for every convolution layer until the receptive\n",
        "           field becomes the size of the image\n",
        "2. The model seems to over train  as we are trying to find a lot of edges and gradients from images of \n",
        "     28 * 28 size\n",
        "3. The Number of classes are 10 where as we are using a lot of kernels ( 32- 2048 ). That creates a lot of image in the memory and the processor becomes very slow due to excessive use of the memory\n",
        "4. The Accuracy of the model is less as the model over trains itself \n",
        "\n",
        "**Major Problem Identified **\n",
        "\n",
        "The Model directly lowers the number of kernels from 2048 to 10. This takes out all the major learnings that the model learned by performing multiple convolution operations. Hence the accuracy is very low \n",
        "\n",
        "**Fix**\n",
        "\n",
        "It's important to preserve the understanding/learning by using a 1*  1 kernel and 10 of them. By doing this we will fit the features of all those 2048 channels into 10 and then perform a convolution of 3* 3 and 10 of them in order to map it to the number of output classes.\n",
        "\n",
        "The following is the code which fixed the problem and got a better accuracy\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "      \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOl2VbxAnWJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8075dfae-863f-4c16-fb5b-e0b6ff9fde2b"
      },
      "source": [
        "\n",
        "from keras.layers import Activation, MaxPooling2D\n",
        "\n",
        "model = Sequential() \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1))) \n",
        "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
        "\n",
        "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(1024, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(2048, 3, 3, activation='relu'))\n",
        "# This layer is added to preserve the learning for future steps.\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 3, 3, activation='relu')) \n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(y_pred[:9])\n",
        "print(y_test[:9])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 22, 22, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 5, 5, 1024)        4719616   \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 3, 3, 2048)        18876416  \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 3, 3, 10)          20490     \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 1, 1, 10)          910       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,185,432\n",
            "Trainable params: 25,185,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 114s 2ms/step - loss: 0.2386 - acc: 0.9258\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0624 - acc: 0.9825\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0472 - acc: 0.9866\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0409 - acc: 0.9885\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0337 - acc: 0.9902\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0299 - acc: 0.9912\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0259 - acc: 0.9929\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0218 - acc: 0.9939\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0230 - acc: 0.9937\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 112s 2ms/step - loss: 0.0219 - acc: 0.9942\n",
            "[[6.0274431e-08 6.0274431e-08 1.6105935e-04 2.4484476e-05 5.3299067e-07\n",
            "  6.0274431e-08 6.0274431e-08 9.9980873e-01 7.3240287e-08 4.7591097e-06]\n",
            " [1.5868148e-08 1.5868148e-08 9.9999988e-01 1.5868148e-08 1.5868148e-08\n",
            "  1.5868148e-08 1.5868148e-08 1.5868148e-08 1.5868148e-08 1.5868148e-08]\n",
            " [3.2852734e-10 1.0000000e+00 6.4523437e-10 3.2852734e-10 7.4730527e-10\n",
            "  3.3943146e-10 6.4188699e-10 3.2852734e-10 2.7191767e-09 3.2852734e-10]\n",
            " [1.0000000e+00 1.4994866e-11 2.8755406e-10 1.4045059e-11 3.0124516e-12\n",
            "  6.2672922e-11 9.4755030e-09 1.8377030e-08 2.9243524e-10 3.0124516e-12]\n",
            " [8.5900436e-12 4.9867339e-11 8.5900436e-12 8.5900436e-12 1.0000000e+00\n",
            "  8.5900436e-12 8.5900436e-12 1.1799433e-11 1.6349351e-09 1.0807105e-09]\n",
            " [7.7844335e-11 1.0000000e+00 8.6251166e-11 7.7844335e-11 3.0774822e-10\n",
            "  7.7844335e-11 1.1741563e-10 7.7844335e-11 4.1509557e-10 7.7844335e-11]\n",
            " [1.4334655e-07 5.3232378e-07 1.4334655e-07 1.4334655e-07 9.9986804e-01\n",
            "  6.7329972e-07 1.4334655e-07 7.8881595e-07 7.6429518e-05 5.2893134e-05]\n",
            " [5.6895420e-08 1.3326177e-08 1.3326177e-08 1.3326177e-08 3.5960526e-05\n",
            "  8.3307270e-08 1.3326177e-08 1.3326177e-08 4.1571963e-07 9.9996352e-01]\n",
            " [3.2089369e-09 3.2089369e-09 3.2089369e-09 3.2089369e-09 3.2089369e-09\n",
            "  6.0085946e-04 9.9939668e-01 3.2089369e-09 2.4623389e-06 3.2089369e-09]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9AeBfy1FnuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fd1ecc75-9269-477c-b8d1-7034b987eb83"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04412626036056208, 0.9905]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWFvgzxtn_64",
        "colab_type": "text"
      },
      "source": [
        "**Summary **\n",
        "\n",
        "The following points to be considering while designing a Convolution model \n",
        "\n",
        "1. The Size of kernels and number of kernels for each convolution layer must be carefully decided \n",
        "2. The Number of kernels must be in line with the number of classes ( must not be less , must not be high)\n",
        "3. The Hyper parameters must be choosen based on experience and learnings from multiple outcomes \n",
        "4. The Optimizer and Loss function must be choosen carefully and based on the data we are trying to fit \n",
        "5. Proper Normalization technique must be used\n",
        "\n",
        "The Process of getting the best fit model is also iterative in nature and data hungry. Care must be taken to get a perfect fit model and not an overfit or underfit one \n",
        "\n",
        "\n",
        "\n",
        "*********************************************************************************************************************************"
      ]
    }
  ]
}